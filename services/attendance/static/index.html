<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Realtime Face Recognition</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
        }
        .container {
            display: flex;
            flex-direction: column;
            gap: 20px;
        }
        .video-container {
            position: relative;
            width: 640px;
            height: 480px;
        }
        #videoElement {
            position: absolute;
            width: 100%;
            height: 100%;
            object-fit: cover;
        }
        #canvasOutput {
            position: absolute;
            width: 100%;
            height: 100%;
            z-index: 10;
        }
        .controls {
            display: flex;
            gap: 10px;
            margin-bottom: 10px;
        }
        .results {
            border: 1px solid #ccc;
            padding: 10px;
            height: 300px;
            overflow-y: auto;
        }
        table {
            width: 100%;
            border-collapse: collapse;
        }
        th, td {
            border: 1px solid #ddd;
            padding: 8px;
            text-align: left;
        }
        th {
            background-color: #f2f2f2;
        }
        .status {
            padding: 10px;
            margin-bottom: 10px;
            background-color: #f8f9fa;
            border-radius: 4px;
        }
        #errorMessage {
            color: red;
            font-weight: bold;
            margin: 10px 0;
        }
    </style>
</head>
<body>
    <h1>Realtime Face Recognition</h1>
    
    <div class="container">
        <div class="controls">
            <button id="startButton" disabled>Start Camera</button>
            <button id="stopButton" disabled>Stop Camera</button>
            <label for="threshold">Recognition Threshold:</label>
            <input type="range" id="threshold" min="0.1" max="0.9" step="0.1" value="0.6">
            <span id="thresholdValue">0.6</span>
            <label for="location">Location:</label>
            <input type="text" id="location" placeholder="Optional location name">
        </div>
        
        <div class="status" id="status">
            Loading OpenCV.js...
        </div>
        <div id="errorMessage"></div>
        
        <div class="video-container">
            <video id="videoElement" autoplay playsinline></video>
            <canvas id="canvasOutput"></canvas>
        </div>
        
        <div>
            <h2>Recognition Results</h2>
            <div class="results" id="results">
                <table id="resultsTable">
                    <thead>
                        <tr>
                            <th>Time</th>
                            <th>Recognized</th>
                            <th>Unknown</th>
                            <th>Total</th>
                            <th>Students</th>
                        </tr>
                    </thead>
                    <tbody id="resultsBody">
                    </tbody>
                </table>
            </div>
        </div>
    </div>

    <!-- Load OpenCV.js -->
    <script src="opencv.js" async onload="onOpenCvScriptLoaded()" onerror="onOpenCvError()"></script>

    <script>
        // UI Elements
        let video = document.getElementById('videoElement');
        let canvasOutput = document.getElementById('canvasOutput');
        let startButton = document.getElementById('startButton');
        let stopButton = document.getElementById('stopButton');
        let thresholdSlider = document.getElementById('threshold');
        let thresholdValue = document.getElementById('thresholdValue');
        let locationInput = document.getElementById('location');
        let status = document.getElementById('status');
        let errorMessage = document.getElementById('errorMessage');
        let resultsBody = document.getElementById('resultsBody');
        
        // Global variables
        let streaming = false;
        let stream = null;
        let socket = null;
        let faceCascadePath = 'haarcascade_frontalface_default.xml';
        let faceCascade;
        let src, gray, dst;
        let frameCount = 0;
        let sendInterval = 5; // Send every 5th frame to reduce load
        
        // Called when OpenCV.js script is loaded
        function onOpenCvScriptLoaded() {
            status.textContent = 'OpenCV.js script loaded. Waiting for OpenCV to initialize...';
        }
        
        // Called if OpenCV.js fails to load
        function onOpenCvError() {
            status.textContent = 'Failed to load OpenCV.js!';
            errorMessage.textContent = 'Could not load OpenCV.js. Please check if the file exists in the correct location.';
        }
        
        // Called when OpenCV.js is ready to use
        function onOpenCvReady() {
            status.textContent = 'OpenCV.js is ready. Click "Start Camera" to begin.';
            startButton.disabled = false;
            
            // Update threshold value display
            thresholdSlider.addEventListener('input', function() {
                thresholdValue.textContent = this.value;
            });
            
            // Start camera event
            startButton.addEventListener('click', startCamera);
            
            // Stop camera event
            stopButton.addEventListener('click', stopCamera);
        }
        
        // Start camera and face detection
        async function startCamera() {
            try {
                // Initialize camera
                stream = await navigator.mediaDevices.getUserMedia({
                    video: { width: 640, height: 480 },
                    audio: false
                });
                
                video.srcObject = stream;
                // Set up face detection (without cascade for now)
                status.textContent = 'Camera starting. Waiting for video to load...';
                startButton.disabled = true;
                stopButton.disabled = false;
                
                // Wait for video to be playing before starting processing
                video.onloadedmetadata = function() {
                    // Set canvas size based on actual video size
                    canvasOutput.width = video.videoWidth;
                    canvasOutput.height = video.videoHeight;
                    
                    // Start playing the video
                    video.play();
                };
                
                // Wait until the video is actually playing and has dimensions
                video.onplaying = function() {
                    status.textContent = 'Camera started. Face detection will begin soon...';
                    
                    // Wait a short moment to ensure video is actually playing
                    setTimeout(() => {
                        // Set up WebSocket
                        connectWebSocket();
                        
                        // Start processing video (without face detection initially)
                        streaming = true;
                        processVideo();
                    }, 500);
                };
                
                // Load face cascade after starting camera
                loadFaceCascade();
                
            } catch (error) {
                console.error('Error starting camera:', error);
                status.textContent = 'Failed to start camera.';
                errorMessage.textContent = 'Error: ' + error.message;
            }
        }
        
        // Load face cascade file
        function loadFaceCascade() {
            try {
                status.textContent = 'Loading face detection cascade...';
                
                // Create file from URL utility
                function createFileFromUrl(url, callback) {
                    let request = new XMLHttpRequest();
                    request.open('GET', url, true);
                    request.responseType = 'arraybuffer';
                    request.onload = function(ev) {
                        if (request.readyState === 4) {
                            if (request.status === 200) {
                                let data = new Uint8Array(request.response);
                                cv.FS_createDataFile('/', faceCascadePath, data, true, false, false);
                                callback();
                            } else {
                                errorMessage.textContent = 'Failed to load cascade file: ' + request.status;
                            }
                        }
                    };
                    request.send();
                }
                
                // Load the cascade file
                createFileFromUrl(faceCascadePath, () => {
                    try {
                        // Create cascade classifier
                        faceCascade = new cv.CascadeClassifier();
                        faceCascade.load(faceCascadePath);
                        
                        // Check if loaded successfully
                        if (faceCascade.empty()) {
                            errorMessage.textContent = 'Failed to load cascade - file may be corrupted';
                            status.textContent = 'Face detection not available.';
                        } else {
                            status.textContent = 'Face detection enabled.';
                            errorMessage.textContent = '';
                        }
                    } catch (err) {
                        console.error('Error loading cascade classifier:', err);
                        errorMessage.textContent = 'Error initializing face detection: ' + err.message;
                    }
                });
            } catch (error) {
                console.error('Error setting up face detection:', error);
                errorMessage.textContent = 'Error setting up face detection: ' + error.message;
            }
        }
        
        // Stop camera and face detection
        function stopCamera() {
            if (streaming) {
                // Stop streaming
                streaming = false;
                
                // Close WebSocket
                if (socket && socket.readyState === WebSocket.OPEN) {
                    socket.close();
                }
                
                // Stop camera
                if (stream) {
                    stream.getTracks().forEach(track => track.stop());
                }
                
                // Reset UI
                startButton.disabled = false;
                stopButton.disabled = true;
                status.textContent = 'Camera stopped.';
                
                // Clean up OpenCV resources
                cleanupOpenCvResources();
            }
        }
        
        // Clean up OpenCV resources
        function cleanupOpenCvResources() {
            try {
                if (src) {
                    src.delete();
                    src = null;
                }
                if (dst) {
                    dst.delete();
                    dst = null;
                }
                if (gray) {
                    gray.delete();
                    gray = null;
                }
                if (faceCascade) {
                    faceCascade.delete();
                    faceCascade = null;
                }
            } catch (e) {
                console.error('Error cleaning up resources:', e);
            }
        }
        
        // Connect to WebSocket server
        function connectWebSocket() {
            // Create WebSocket connection
            const wsProtocol = window.location.protocol === 'https:' ? 'wss://' : 'ws://';
            const wsUrl = `${wsProtocol}${window.location.host}/realtime/face-recognition`;
            
            socket = new WebSocket(wsUrl);
            
            socket.onopen = function() {
                status.textContent += ' WebSocket connected.';
            };
            
            socket.onclose = function() {
                status.textContent = 'WebSocket connection closed.';
            };
            
            socket.onerror = function(error) {
                console.error('WebSocket error:', error);
                errorMessage.textContent = 'WebSocket connection error. Backend service may not be available.';
            };
            
            socket.onmessage = function(event) {
                try {
                    const response = JSON.parse(event.data);
                    logResults(response);
                } catch (error) {
                    console.error('Error parsing WebSocket response:', error);
                }
            };
        }
        
        // Simple approach that avoids OpenCV.js for video capture
        function processVideo() {
            if (!streaming) {
                return;
            }
            
            try {
                // Make sure video element is properly initialized
                if (!video.videoWidth || !video.videoHeight || video.videoWidth === 0 || video.videoHeight === 0) {
                    console.log("Video dimensions not ready yet, waiting...");
                    requestAnimationFrame(processVideo);
                    return;
                }
                
                // Make sure canvas is properly sized
                if (canvasOutput.width !== video.videoWidth || canvasOutput.height !== video.videoHeight) {
                    canvasOutput.width = video.videoWidth;
                    canvasOutput.height = video.videoHeight;
                }
                
                // Get canvas context
                const ctx = canvasOutput.getContext('2d');
                
                // Draw video frame on canvas
                ctx.drawImage(video, 0, 0, canvasOutput.width, canvasOutput.height);
                
                // Get image data for face detection
                const imageData = ctx.getImageData(0, 0, canvasOutput.width, canvasOutput.height);
                
                // Do face detection if cascade is loaded
                if (faceCascade && !faceCascade.empty()) {
                    try {
                        // Convert imageData to Mat
                        let src = cv.matFromImageData(imageData);
                        let gray = new cv.Mat();
                        
                        // Convert to grayscale
                        cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY);
                        
                        // Detect faces
                        let faces = new cv.RectVector();
                        faceCascade.detectMultiScale(gray, faces, 1.1, 3, 0);
                        
                        // Draw rectangles around faces
                        for (let i = 0; i < faces.size(); ++i) {
                            let face = faces.get(i);
                            ctx.strokeStyle = 'green';
                            ctx.lineWidth = 2;
                            ctx.strokeRect(face.x, face.y, face.width, face.height);
                        }
                        
                        // Clean up resources
                        src.delete();
                        gray.delete();
                        faces.delete();
                    } catch (e) {
                        console.error('Face detection error:', e);
                    }
                }
                
                // Send frame to backend for recognition
                frameCount++;
                if (frameCount % sendInterval === 0 && socket && socket.readyState === WebSocket.OPEN) {
                    sendFrameToBackend(canvasOutput);
                }
                
                // Continue processing
                requestAnimationFrame(processVideo);
                
            } catch (err) {
                console.error('Error in processVideo:', err);
                errorMessage.textContent = 'Error processing video: ' + err.message;
                
                // Try to continue despite errors
                requestAnimationFrame(processVideo);
            }
        }
        
        // Send frame to backend
        function sendFrameToBackend(canvas) {
            try {
                // Get base64 image from canvas
                const imageData = canvas.toDataURL('image/jpeg', 0.7);
                const base64Data = imageData.split(',')[1];
                
                // Create data to send
                const data = {
                    image_base64: base64Data,
                    threshold: parseFloat(thresholdSlider.value),
                    location: locationInput.value || null
                };
                
                // Send to server
                socket.send(JSON.stringify(data));
                
            } catch (error) {
                console.error('Error sending frame to backend:', error);
                errorMessage.textContent = 'Error sending frame to backend: ' + error.message;
            }
        }
        
        // Log recognition results
        function logResults(response) {
            if (!response.success) {
                console.error('Recognition error:', response.message);
                errorMessage.textContent = 'Recognition error: ' + response.message;
                return;
            }
            
            // Create a new row in the results table
            const row = document.createElement('tr');
            
            // Format timestamp
            const now = new Date();
            const timestamp = now.toLocaleTimeString();
            
            // Create cells
            const timeCell = document.createElement('td');
            timeCell.textContent = timestamp;
            
            const recognizedCell = document.createElement('td');
            recognizedCell.textContent = response.recognized_count;
            
            const unknownCell = document.createElement('td');
            unknownCell.textContent = response.unknown_count;
            
            const totalCell = document.createElement('td');
            totalCell.textContent = response.total_faces_detected;
            
            const studentsCell = document.createElement('td');
            if (response.students && response.students.length > 0) {
                studentsCell.textContent = response.students.map(s => s.name).join(', ');
            } else {
                studentsCell.textContent = 'None';
            }
            
            // Add cells to row
            row.appendChild(timeCell);
            row.appendChild(recognizedCell);
            row.appendChild(unknownCell);
            row.appendChild(totalCell);
            row.appendChild(studentsCell);
            
            // Add row to table
            resultsBody.prepend(row);
            
            // Limit table rows
            if (resultsBody.children.length > 100) {
                resultsBody.removeChild(resultsBody.lastChild);
            }
            
            // Clear any error messages
            errorMessage.textContent = '';
        }
        
        // Setup OpenCV when it's ready
        function onOpenCvLoaded() {
            onOpenCvReady();
        }
        
        // Check if OpenCV.js is already loaded
        if (typeof cv !== 'undefined' && cv.Mat) {
            onOpenCvReady();
        } else {
            // If not loaded yet, set the callback
            window.Module = {
                onRuntimeInitialized: onOpenCvLoaded
            };
        }
    </script>
</body>
</html>